name: Benchmarks

on:
  push:
    branches: [main]
  schedule:
    - cron: '0 0 * * 0'  # Weekly on Sunday at midnight UTC
  workflow_dispatch:
    inputs:
      update_baseline:
        description: 'Update baseline with current results'
        required: false
        type: boolean
        default: false

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  FORCE_COLOR: "1"
  UV_SYSTEM_PYTHON: "1"

jobs:
  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          enable-cache: true
          cache-dependency-glob: "pyproject.toml"

      - name: Set up Python
        run: uv python install 3.13

      - name: Install dependencies
        run: |
          uv sync --extra dev
          uv pip install mutmut psutil

      - name: Run benchmarks
        run: |
          uv run python benchmarks/run_benchmarks.py \
            --project synthetic \
            --runs 3 \
            --output benchmarks/results/

      - name: Find latest results file
        id: find_results
        run: |
          LATEST=$(ls -t benchmarks/results/benchmark_*.json | head -1)
          echo "results_file=$LATEST" >> $GITHUB_OUTPUT
          echo "Found results file: $LATEST"

      - name: Check for regression
        id: check_regression
        run: |
          uv run python benchmarks/check_regression.py \
            --baseline benchmarks/baseline.json \
            --current "${{ steps.find_results.outputs.results_file }}" \
            --threshold 10 | tee regression_report.txt
        continue-on-error: true

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.sha }}
          path: |
            benchmarks/results/
            regression_report.txt
          retention-days: 90

      - name: Create comment body file
        run: |
          # Find the markdown report
          REPORT=$(ls -t benchmarks/results/benchmark_*.md | head -1)

          # Create comment body with results summary
          {
            echo '## Benchmark Results'
            echo ''
            head -60 "$REPORT"
            echo ''
            echo '---'
            echo ''
            echo '### Regression Check'
            cat regression_report.txt
            echo ''
            echo "[Full results artifact](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})"
          } > comment_body.md

      - name: Comment on commit
        if: github.event_name == 'push'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const body = fs.readFileSync('comment_body.md', 'utf8');

            await github.rest.repos.createCommitComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              commit_sha: context.sha,
              body: body
            });

      - name: Update baseline
        if: github.event_name == 'workflow_dispatch' && inputs.update_baseline
        env:
          RESULTS_FILE: ${{ steps.find_results.outputs.results_file }}
        run: |
          # Extract just the timing data for baseline
          uv run python -c "
          import json
          import os
          from pathlib import Path

          results_file = os.environ['RESULTS_FILE']
          data = json.loads(Path(results_file).read_text())
          baseline = {}
          for summary in data.get('summaries', []):
              key = f\"{summary['tool']}_{summary['config']}\"
              baseline[key] = round(summary['mean_time'], 2)

          Path('benchmarks/baseline.json').write_text(json.dumps(baseline, indent=2) + '\n')
          print('Updated baseline.json:')
          print(json.dumps(baseline, indent=2))
          "

          # Commit and push the updated baseline
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add benchmarks/baseline.json
          git commit -m "chore: update benchmark baseline [skip ci]" || echo "No changes to commit"
          git push

      - name: Fail on regression
        if: steps.check_regression.outcome == 'failure'
        run: |
          echo "Performance regressions detected!"
          cat regression_report.txt
          exit 1
